# Building a Recommendation system: creating an item based collaborative filtering to recommend top 5 movies to users. ğŸš€

![Project Image](https://github.com/AmirFARES/Kaggle-Spaceship-Titanic/blob/main/imgs/spaceship.jpg)

## Introduction ğŸŒŸ
Here is my Phase 4 project for creating a Recommender system. I'm creating a recommender system on an item based collaborative filtering which provides top 5 movie Recommendation to users based on their ratings

## About the Challenge ğŸŒ
Hollywood movie studio aims to enhance the user engagement and its revenue by implementing an item-based-recommender system that suggest movies which are similar to the other users might have rated. Lets leverage the movie similarities based on the attributes like ratings and title as we seek to improve content and provide a highly personalized experience. The recommender systems built provides top 5 movie recommendations to a user, based on their ratings of other movies.


### Objectives ğŸ“
1. Retrieve the top 5 movie title recommended to user based on their ratings

2. Enable users explore a wide range of films similar to their preferences

3. Drive users subscriptions by suggesting appealing content


## Project Files ğŸ“‚

Key files related to this project:
We were provided two dataset, movies.csv, ratings.csv

## My Approach ğŸš€

1. **Reading Datasets**: I began by loading the provided datasets, both the rating.csv and movies.csv

2. **Handling Missing Values**: I checked missing data in the dataset, ensuring that no valuable information was lost.

3. **Creating a cleaned csv file**:  I created a cleaned csv file movie_ratings_df

4. **Data Visuakization** : I perform some visualization on the train csv to check for the features that affected the rate of transportation on the passengers

<img src="https://github.com/AmirFARES/Kaggle-Spaceship-Titanic/blob/main/imgs/correlationHeatmap.png" alt="Line Chart" width="700" height="437">

5. **Feature Engineering**: To improve model performance, I engineered new features. For example, I extracted additional information from the "numeric" column that had expenditure, summing them to the spending cost 

6. **One-Hot Encoding**: I prepared the categorical data for modeling by performing one-hot encoding, a necessary step for many machine learning models.

7. **Scaling**: I prepared the numeric data for modeling by performing scaling which is a necessary step for data Normalization.

8. **Extracting (X, y)**: I separated the feature matrix (X) and the target variable (y) from the training dataset, ensuring that the data was ready for model training.

9. **Creating the Models**: I created my baseline logistic regression model which was my reference model, then evaluated the accuracy score, plotted the ROC curve. I also improved my baseline model by applying the following model:
     - DecisionTreeClassifier
     - RandomForestClassifier
     - I performed tuning on these models to optimize their performance, checked its accuracy score and finally created the ROC curve 

10. **Making Predictions**: I got the predictions from the three models.

11. **Conclusion and Recommendations**: I gave few conclusion and recommendations i derived from the data


## Connect with Me ğŸ“«

I'm open to collaboration and eager to learn from the data science community. You can find more of my projects on [GitHub](https://github.com/mikabenson/Space_ship-project)).


